{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b31be28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import json\n",
    "import os\n",
    "from typing import List, Tuple\n",
    "import uuid\n",
    "import re\n",
    "import pandas as pd\n",
    "import ast\n",
    "from datetime import datetime\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Globals"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "SEP_TOPIC = \"_\"\n",
    "MINIMUM_CONFIDENCE = 0.9"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "61871cb4",
   "metadata": {},
   "source": [
    "## Utilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f48b9d",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def plural(palavra: str) -> str:\n",
    "    \"\"\"\n",
    "    Passa uma palavra em português para o plural. Não funciona sempre,\n",
    "    devido à quantidade de exceções que precisam ser programadas à mão.\n",
    "    \"\"\"\n",
    "    palavra = palavra.strip()\n",
    "    # se for vazia ou mais de uma palavra, retorna sem alterar\n",
    "    if not palavra or len(palavra.split(\" \")) > 1:\n",
    "        return palavra\n",
    "    # se a palavra no plural é igual no singular, retorna sem alterar\n",
    "    invariaveis = [r\"x$\"]\n",
    "    for p in invariaveis:\n",
    "        if re.search(p, palavra):\n",
    "            return palavra\n",
    "    substituicoes = {\n",
    "        r\"ão\": r\"õe\",\n",
    "        r\"r$\": r\"re\",\n",
    "        r\"z$\": r\"ze\",\n",
    "        r\"(?<=[aeou])l\": r\"i\",\n",
    "        r\"il\": r\"ei\",\n",
    "        r\"m$\": r\"n\",\n",
    "    }\n",
    "    for p, s in substituicoes.items():\n",
    "        palavra = re.sub(p, s, palavra)\n",
    "    return palavra + \"s\" if palavra[-1] != \"s\" else palavra\n",
    "\n",
    "def sanitize(palavra: str) -> str:\n",
    "    \"\"\"Substitui caracteres acentuados.\"\"\"\n",
    "    substituicoes = {\n",
    "        \"a\": [\"á\", \"â\", \"ã\", \"à\"],\n",
    "        \"c\": [\"ç\"],\n",
    "        \"e\": [\"é\", \"ê\"],\n",
    "        \"i\": [\"í\"],\n",
    "        \"o\": [\"ó\", \"ô\", \"õ\"],\n",
    "        \"u\": [\"ú\", \"ü\"],\n",
    "    }\n",
    "    for substituta, letras in substituicoes.items():\n",
    "        for letra in letras:\n",
    "            palavra = palavra.replace(letra, substituta)\n",
    "    return palavra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bdc81f",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def drop_duplicates(ls: list) -> list:\n",
    "    \"\"\"Remove elementos duplicados ou vazios.\"\"\"\n",
    "    return list(filter(None, set(ls)))\n",
    "\n",
    "def flatten(ls: list) -> list:\n",
    "    \"\"\"Reduz em 1 a dimensão de uma lista.\"\"\"\n",
    "    return [item for sublist in ls for item in sublist]\n",
    "\n",
    "def remove(ls: list, to_remove: list) -> list:\n",
    "    \"\"\"Remove de uma lista quaisquer elementos que estejam em outra.\"\"\"\n",
    "    return [item for item in ls if item not in to_remove]\n",
    "\n",
    "def inner_join(a: list, b: list):\n",
    "    return [v for v in a + b if v in a and v in b]\n",
    "\n",
    "def is_flat(x) -> bool:\n",
    "    \"\"\"Retorna verdadeiro se a entrada não for um dicionário nem uma lista.\"\"\"\n",
    "    return not (isinstance(x, list) or isinstance(x, dict))\n",
    "\n",
    "def is_flat_list(x) -> bool:\n",
    "    \"\"\"Retorna verdadeiro se a lista for plana.\"\"\"\n",
    "    return all(is_flat(y) for y in x)\n",
    "\n",
    "def mix_list(a, b) -> list:\n",
    "    \"\"\"\n",
    "    Realiza um outer join entre duas listas planas ou que contêm dicionários.\n",
    "    \"\"\"\n",
    "    if is_flat_list(a) and is_flat_list(b):\n",
    "        return drop_duplicates(a + b)\n",
    "    elif is_flat_list(a) or is_flat_list(b):\n",
    "        raise ValueError(a, b)\n",
    "\n",
    "    a_keys = get_possible_global_keys(a)\n",
    "    b_keys = get_possible_global_keys(b)\n",
    "    common_keys = inner_join(a_keys, b_keys)\n",
    "    hardcoded_precedence = {\"conditions\": 1, \"title\": 0}\n",
    "    if len(common_keys) > 0:\n",
    "        common_keys.sort(key=lambda x: hardcoded_precedence.get(x, 999))\n",
    "        a_key = common_keys[0]\n",
    "        b_key = a_key\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Different global keys were found for each list: {a_keys} \"\n",
    "            f\"and {b_keys}, respectively\"\n",
    "        )\n",
    "\n",
    "    a_dict = {subdict[a_key]: subdict for subdict in a}\n",
    "    b_dict = {subdict[b_key]: subdict for subdict in b}\n",
    "    mixed_dicts = mix_dict(a_dict, b_dict)\n",
    "    return list(mixed_dicts.values())\n",
    "\n",
    "def get_possible_global_keys(ls: List[dict]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Transforma uma lista de dicionários em um dicionário de dicionários,\n",
    "    inferindo como chave para cada dict algum valor dele que seja presente\n",
    "    em todos os dicts, único em cada um e plano.\n",
    "    \"\"\"\n",
    "    d = ls[0]\n",
    "    global_keys = []\n",
    "    for key in d:\n",
    "        # se o valor dessa chave não for plano\n",
    "        if not is_flat(d[key]):\n",
    "            # print(key, \"is not flat\")\n",
    "            continue\n",
    "        # se nem todos dicts tiverem essa chave\n",
    "        if not all(key in d_ for d_ in ls):\n",
    "            # print(key, \"is not in every dict\")\n",
    "            continue\n",
    "        # se nem todos os dicts tiverem um valor para essa chave\n",
    "        if not all(bool(d_[key]) for d_ in ls):\n",
    "            # print(key, \"doesnt have a value in all dicts\")\n",
    "            continue\n",
    "        # se cada dict não tiver um valor único para essa chave\n",
    "        if not len(set(d_[key] for d_ in ls)) == len(ls):\n",
    "            # print(key, \"doesnt have all unique values\")\n",
    "            continue\n",
    "        global_keys.append(key)\n",
    "\n",
    "    if not global_keys:\n",
    "        raise ValueError(f\"Could not find any global key for {ls}\")\n",
    "    return global_keys\n",
    "\n",
    "def mix_dict(a: dict, b: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Retorna um dicionário contendo as chaves e valores de ambos dicionários\n",
    "    de entrada, dando preferência para os valores de b.\n",
    "    \"\"\"\n",
    "    out = deepcopy(b)\n",
    "    for k, v in a.items():\n",
    "        if k not in out:\n",
    "            out[k] = v\n",
    "        elif isinstance(v, list):\n",
    "            if not isinstance(b[k], list):\n",
    "                raise ValueError(f\"a é uma lista em {k}, mas b é {type(b[k])}\")\n",
    "            out[k] = mix_list(v, b[k])\n",
    "        elif isinstance(v, dict):\n",
    "            if not isinstance(b[k], dict):\n",
    "                raise ValueError(f\"a é um dict em {k}, mas b é {type(b[k])}\")\n",
    "            out[k] = mix_dict(v, b[k])\n",
    "        else:\n",
    "            out[k] = v\n",
    "    return out\n",
    "\n",
    "def remove_nans(d: dict) -> dict:\n",
    "    \"\"\"Removes keys with nan value from a dict.\"\"\"\n",
    "    return {k : v for k, v in d.items() if v == v}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7461f97c",
   "metadata": {},
   "source": [
    "## I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440dc023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_questions() -> pd.DataFrame:\n",
    "    df = pd.read_excel(\"results/Perguntas.xlsx\", sheet_name=\"finais\")\n",
    "    df = df.dropna(subset=[\"Resposta\"])\n",
    "    subs = {\n",
    "        \"Pergunta\": \"pergunta\",\n",
    "        \"Resposta\": \"resposta\",\n",
    "        \"Fonte\": \"fonte\",\n",
    "        \"Intenção\": \"intent\",\n",
    "        \"Rótulos\": \"rótulos\",\n",
    "        \"Modificador\": \"modificador\",\n",
    "        \"Substantivo\": \"substantivo\",\n",
    "        \"Recipiente\": \"recipiente\",\n",
    "        \"Elocuções\": \"examples\",\n",
    "    }\n",
    "    df = df[list(subs.keys())]\n",
    "    df = df.rename(columns=subs)\n",
    "    df = df.fillna(\"\")\n",
    "    return df\n",
    "\n",
    "def load_skill(file_path: str) -> dict:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        sk = json.load(f)\n",
    "    return sk\n",
    "\n",
    "def save_skill(file_path: str, to_save: dict):\n",
    "    root, extension = os.path.splitext(file_path)\n",
    "    new_skill_path = f\"{root}2{extension}\"\n",
    "    with open(new_skill_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(to_save, f, ensure_ascii=False, indent=4)\n",
    "    print(f\"Skill saved as {new_skill_path}!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5dfb0c",
   "metadata": {},
   "source": [
    "## Intenções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d50825",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intents(df: pd.DataFrame) -> dict:\n",
    "    subset = [\"intent\", \"pergunta\", \"examples\"]\n",
    "    records = df[subset].to_dict(orient=\"records\")\n",
    "    intents = [\n",
    "        {\n",
    "            \"intent\": record[\"intent\"].replace(\"-\", \" \"),\n",
    "            \"examples\": get_examples(record),\n",
    "            \"description\": \"\",\n",
    "        }\n",
    "        for record in records\n",
    "    ]\n",
    "    intents.sort(key=lambda x: x[\"intent\"])\n",
    "    return intents\n",
    "\n",
    "def get_examples(record: dict) -> List:\n",
    "    # a própria pergunta é um exemplo\n",
    "    out = [{\"text\": record[\"pergunta\"]}]\n",
    "    # tudo que está em Elocuções é exemplo também\n",
    "    if record[\"examples\"]:\n",
    "        out += [{\"text\": exemplo} for exemplo in record[\"examples\"].split(\"--\")]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a808686f",
   "metadata": {},
   "source": [
    "## Entidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8def953b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities(df):\n",
    "    subset = [\"rótulos\", \"modificador\", \"substantivo\", \"recipiente\"]\n",
    "    entities = [\n",
    "        {\"entity\": col, \"values\": get_entity_values(df[col]), \"fuzzy_match\": True}\n",
    "        for col in subset\n",
    "    ]\n",
    "    entities.sort(key=lambda x: x[\"entity\"])\n",
    "    return entities\n",
    "\n",
    "def get_entity_values(series):\n",
    "    records = series.to_list()\n",
    "    records = drop_duplicates(records)\n",
    "    records = [r.replace(\"-\", \" \") for r in records]\n",
    "    values = [\n",
    "        {\"type\": \"synonyms\", \"value\": record, \"synonyms\": []} for record in records\n",
    "    ]\n",
    "    return values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b903d3",
   "metadata": {},
   "source": [
    "## Nós de diálogo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d136d467",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_dialog_nodes(df: pd.DataFrame) -> dict:\n",
    "    records = df.to_dict(orient=\"records\")\n",
    "    nodes = [\n",
    "        {\n",
    "            \"type\": \"standard\",\n",
    "            \"title\": get_titulo(record),\n",
    "            \"output\": {\n",
    "                \"generic\": [\n",
    "                    {\n",
    "                        \"values\": [{\"text\": record[\"resposta\"]}],\n",
    "                        \"response_type\": \"text\",\n",
    "                        \"selection_policy\": \"sequential\",\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "            \"context\": {\"contexto\": sanitize(record[\"rótulos\"].replace(\"-\", \" \"))},\n",
    "            \"conditions\": get_all_conditions(record),\n",
    "            \"dialog_node\": f\"node_{uuid.uuid4().hex[:16]}\",\n",
    "            \"fonte\": record[\"fonte\"],\n",
    "            \"intent\": record[\"intent\"],\n",
    "            \"modificador\": record[\"modificador\"],\n",
    "            \"substantivo\": record[\"substantivo\"],\n",
    "            \"recipiente\": record[\"recipiente\"],\n",
    "        }\n",
    "        for record in records\n",
    "    ]\n",
    "    nodes.sort(key=lambda x: x[\"conditions\"])\n",
    "    return nodes\n",
    "\n",
    "def get_titulo(js: dict) -> str:\n",
    "    \"\"\"\n",
    "    Retorna um título para o nó baseado no modificador, substantivo, recipiente\n",
    "    e rótulos.\n",
    "    :param js: nó\n",
    "    :return: título\n",
    "    \"\"\"\n",
    "    modificador = js[\"modificador\"].replace(\"-\", \" \")\n",
    "    substantivo = js[\"substantivo\"].replace(\"-\", \" \")\n",
    "    recipiente = js[\"recipiente\"].replace(\"-\", \" \")\n",
    "\n",
    "    contextos = get_contextos(js[\"rótulos\"].split(\"_\"))\n",
    "    contextos = list(map(lambda x: x.replace(\"-\", \" \"), contextos))\n",
    "    contexto = f\"{'/'.join(contextos)}\"\n",
    "    trechos = []\n",
    "\n",
    "    if modificador in [\"definição\"]:\n",
    "        trechos.append(modificador)\n",
    "        if substantivo:\n",
    "            trechos.append(f\"de {substantivo}\")\n",
    "        if recipiente:\n",
    "            trechos.append(f\"de {recipiente}?\")\n",
    "        else:\n",
    "            trechos.append(f\"de {contexto}?\")\n",
    "    elif modificador in [\"detalhar\"]:\n",
    "        if not (contexto or recipiente):\n",
    "            raise ValueError(\n",
    "                f\"Perguntas do tipo 'detalhar' precisam ter um rótulo\"\n",
    "                f\"contextual ou recipiente! Pergunta: {js['pergunta']}\"\n",
    "            )\n",
    "        trechos.append(modificador)\n",
    "        if substantivo:\n",
    "            trechos.append(f\"{substantivo}\")\n",
    "        if recipiente:\n",
    "            trechos.append(f\"de {recipiente}\")\n",
    "        if contexto:\n",
    "            trechos.append(f\"de {contexto}\")\n",
    "    elif modificador in [\"diferença\"]:\n",
    "        trechos.append(modificador)\n",
    "        trechos.append(f\"entre {substantivo}\")\n",
    "        trechos.append(f\"e {recipiente or contextos[0]}?\")\n",
    "    elif modificador in [\"efeito\"]:\n",
    "        if contexto:\n",
    "            trechos.append(contexto + \":\")\n",
    "        trechos.append(modificador)\n",
    "        if substantivo:\n",
    "            trechos.append(f\"de {substantivo}\")\n",
    "        trechos.append(f\"em {recipiente or contextos[0]}?\")\n",
    "    elif modificador in [\"existe\"]:\n",
    "        if not recipiente:\n",
    "            raise ValueError(\n",
    "                f\"Perguntas do tipo 'exist' precisam de recipiente! \"\n",
    "                f\"Pergunta: {js['pergunta']}\"\n",
    "            )\n",
    "        if contexto:\n",
    "            trechos.append(contexto + \":\")\n",
    "        trechos.append(modificador)\n",
    "        if substantivo:\n",
    "            trechos.append(substantivo)\n",
    "        trechos.append(f\"em {recipiente}?\")\n",
    "    elif modificador in [\"explicar\"]:\n",
    "        if not substantivo:\n",
    "            raise ValueError(\n",
    "                f\"Perguntas do tipo 'explicar' precisam de substantivo! \"\n",
    "                f\"Pergunta: {js['pergunta']}\"\n",
    "            )\n",
    "        trechos.append(modificador)\n",
    "        trechos.append(substantivo)\n",
    "        if recipiente:\n",
    "            trechos.append(f\"de {recipiente}\")\n",
    "        if contexto:\n",
    "            trechos.append(f\"de {contexto}\")\n",
    "    elif modificador in [\"listar\"]:\n",
    "        if substantivo:\n",
    "            if recipiente:\n",
    "                if contexto:\n",
    "                    trechos.append(f\"{contexto}:\")\n",
    "                trechos.append(modificador)\n",
    "                trechos.append(plural(substantivo))\n",
    "                trechos.append(f\"de {recipiente}\")\n",
    "            else:\n",
    "                trechos.append(modificador)\n",
    "                trechos.append(plural(substantivo))\n",
    "                if contexto:\n",
    "                    trechos.append(f\"de {contexto}\")\n",
    "        else:\n",
    "            trechos.append(modificador)\n",
    "            trechos.append(contexto)\n",
    "    elif modificador in [\"localização\"]:\n",
    "        if not (contexto or recipiente):\n",
    "            raise ValueError(\n",
    "                f\"Perguntas do tipo 'detalhar' precisam ter um rótulo\"\n",
    "                f\"contextual ou recipiente! Pergunta: {js['pergunta']}\"\n",
    "            )\n",
    "        trechos.append(modificador)\n",
    "        if substantivo:\n",
    "            trechos.append(f\"de {plural(substantivo)}\")\n",
    "        trechos.append(f\"de {recipiente or contexto}?\")\n",
    "    elif modificador in [\"motivo\"]:\n",
    "        if not (contexto or recipiente):\n",
    "            raise ValueError(\n",
    "                f\"Perguntas do tipo 'motivo' precisam ter um rótulo\"\n",
    "                f\"contextual ou recipiente! Pergunta: {js['pergunta']}\"\n",
    "            )\n",
    "        trechos.append(f\"{modificador} para\")\n",
    "        if substantivo:\n",
    "            trechos.append(f\"{substantivo} de\")\n",
    "        trechos.append(f\"{contexto}?\")\n",
    "    elif modificador in [\"maior\", \"menor\"]:\n",
    "        trechos.append(modificador)\n",
    "        trechos.append(substantivo)\n",
    "        if contexto:\n",
    "            trechos.append(f\"de {contexto}\")\n",
    "        if recipiente:\n",
    "            trechos.append(f\"de {recipiente}\")\n",
    "        trechos.append(\"?\")\n",
    "    elif modificador in [\"maiores\", \"menores\"]:\n",
    "        trechos.append(modificador)\n",
    "        trechos.append(plural(substantivo))\n",
    "        if contexto:\n",
    "            trechos.append(f\"de {contexto}\")\n",
    "        if recipiente:\n",
    "            trechos.append(f\"de {recipiente}\")\n",
    "        trechos.append(\"?\")\n",
    "    elif modificador in [\"pertence\"]:\n",
    "        if not (substantivo or recipiente):\n",
    "            raise ValueError(\n",
    "                f\"Perguntas do tipo 'pertence' precisam de substantivo ou de recipiente! \"\n",
    "                f\"Pergunta: {js['pergunta']}\"\n",
    "            )\n",
    "        trechos.append(f\"{substantivo or contextos[0]} é um {recipiente or contextos[0]}?\")\n",
    "    elif modificador in [\"quantidade\"]:\n",
    "        if not (substantivo or contexto):\n",
    "            raise ValueError(\n",
    "                f\"Perguntas do tipo 'quantidade' precisam ter um rótulo\"\n",
    "                f\"contextual ou substantivo! Pergunta: {js['pergunta']}\"\n",
    "            )\n",
    "        if substantivo:\n",
    "            trechos.append(f\"{contexto}:\")\n",
    "            trechos.append(modificador)\n",
    "            trechos.append(f\"{plural(substantivo)}\")\n",
    "        else:\n",
    "            trechos.append(modificador)\n",
    "            trechos.append(f\"de {contexto}\")\n",
    "        if recipiente:\n",
    "            trechos.append(f\"em {recipiente}\")\n",
    "        trechos.append(\"?\")\n",
    "    elif modificador in [\"responsável\"]:\n",
    "        if not substantivo:\n",
    "            raise ValueError(\n",
    "                f\"Perguntas do tipo 'responsável' precisam de substantivo! \"\n",
    "                f\"Pergunta: {js['pergunta']}\"\n",
    "            )\n",
    "        if not (contexto or recipiente):\n",
    "            raise ValueError(\n",
    "                f\"Perguntas do tipo 'responsável' precisam ter um rótulo\"\n",
    "                f\"contextual ou recipiente! Pergunta: {js['pergunta']}\"\n",
    "            )\n",
    "        trechos.append(modificador)\n",
    "        trechos.append(f\"por {substantivo}\")\n",
    "        trechos.append(f\"de {recipiente or contexto}?\")\n",
    "    else:\n",
    "        raise NotImplementedError(\"Modificador não programado!\")\n",
    "    trechos[0] = trechos[0].capitalize()\n",
    "    titulo = \" \".join(trechos)\n",
    "    titulo = titulo.strip()\n",
    "    substituir = {\n",
    "        \"em amazônia azul\": \"na Amazônia Azul\",\n",
    "        \"de amazônia azul\": \"da Amazônia Azul\",\n",
    "        \"em brasil\": \"no Brasil\",\n",
    "        \"de brasil\": \"no Brasil\",\n",
    "        \"de extinção\": \"em extinção\",\n",
    "        \"de oceano\": \"do oceano\",\n",
    "        \"de governo\": \"do governo\",\n",
    "        \"de mundo\": \"do mundo\",\n",
    "        \"em ambiente\": \"no ambiente\",\n",
    "        \"de branqueamento\": \"do branqueamento\",\n",
    "        \"um tartaruga\": \"uma tartaruga\",\n",
    "        \"de petróleo\": \"do petróleo\",\n",
    "    }\n",
    "    for palavra, substituta in substituir.items():\n",
    "        titulo = titulo.replace(palavra, substituta)\n",
    "    return titulo\n",
    "\n",
    "def get_contextos(rotulos):\n",
    "    \"\"\"\n",
    "    Devolve os contextos de uma pergunta baseado em seus rótulos,\n",
    "    sendo que há uma lista de rótulos que não definem contexto.\n",
    "    \"\"\"\n",
    "    rotulos_nao_contextuais = [\n",
    "        \"fauna\",\n",
    "        \"flora\",\n",
    "        \"outras\",\n",
    "        \"física\",\n",
    "        \"turismo\",\n",
    "        \"saúde\",\n",
    "        \"geologia\",\n",
    "    ]\n",
    "    contextos = [\n",
    "        contexto\n",
    "        for contexto in rotulos\n",
    "        if all(rot not in contexto for rot in rotulos_nao_contextuais)\n",
    "    ]\n",
    "    return contextos\n",
    "\n",
    "def get_all_conditions(js):\n",
    "    modificador = js[\"modificador\"].replace(\"-\", \" \")\n",
    "    substantivo = js[\"substantivo\"].replace(\"-\", \" \")\n",
    "    recipiente = js[\"recipiente\"].replace(\"-\", \" \")\n",
    "    rotulos = js[\"rótulos\"].replace(\"-\", \" \").split(SEP_TOPIC)\n",
    "    rotulos += [js[\"rótulos\"].replace(\"-\", \" \")]\n",
    "    rotulos = drop_duplicates(rotulos)\n",
    "    contextos = get_contextos(rotulos)\n",
    "    # the next part requires at least one element in the list\n",
    "    if not contextos:\n",
    "        contextos = [None]\n",
    "\n",
    "    conds_adicionais = [\n",
    "        get_single_condition(modificador, substantivo, recipiente, contexto)\n",
    "        for contexto in contextos\n",
    "    ]\n",
    "    conds = [f\"#{js['intent']} && intent.confidence > {MINIMUM_CONFIDENCE}\"]\n",
    "    conds += flatten(conds_adicionais)\n",
    "    cond_str = \" || \".join(conds)\n",
    "    return cond_str\n",
    "\n",
    "def get_single_condition(modificador, substantivo, recipiente, contexto) -> list:\n",
    "    trechos = [f'@modificador==\"{modificador}\"']\n",
    "    if substantivo:\n",
    "        trechos.append(f'&& @substantivo==\"{substantivo}\"')\n",
    "    if recipiente:\n",
    "        trechos.append(f'&& @recipiente==\"{recipiente}\"')\n",
    "    cond = \" \".join(trechos)\n",
    "    if contexto:\n",
    "        out = [cond + f' && $contexto==\"{contexto}\"', cond + f' && @rótulos==\"{contexto}\"']\n",
    "    else:\n",
    "        out = [cond]\n",
    "    return out\n",
    "\n",
    "def convert_to_list(df: pd.DataFrame) -> List[dict]:\n",
    "    list_of_dicts = df.to_dict(orient=\"records\")\n",
    "    list_of_dicts = [remove_nans(d) for d in list_of_dicts]\n",
    "    list_of_dicts = [eval_context(d) for d in list_of_dicts]\n",
    "    return list_of_dicts\n",
    "\n",
    "def eval_context(d: dict):\n",
    "    if \"context\" not in d:\n",
    "        return d\n",
    "    context = d[\"context\"]\n",
    "    if isinstance(context, str):\n",
    "        evaluated = ast.literal_eval(context)\n",
    "        d[\"context\"] = evaluated\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class NodeOrganizer:\n",
    "    \"\"\"\n",
    "    Assumes nodes have either been added via the interface (manual) or generated automatically\n",
    "    by this script (generated). There are two special cases: the last node (anything_else),\n",
    "    which was added via interface but must always be the last one, and the root node, where\n",
    "    the dialog begins.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, nodes: List[dict]):\n",
    "        self._df = pd.DataFrame(nodes)\n",
    "        self._extract_intents()\n",
    "        self.anything_else_node = pd.Series(dtype=object)\n",
    "        self.generated_nodes = pd.Series(dtype=object)\n",
    "        self.manual_nodes = pd.Series(dtype=object)\n",
    "        self.root = pd.Series(dtype=object)\n",
    "        self.df_anything_else = pd.DataFrame()\n",
    "        self.df_generated = pd.DataFrame()\n",
    "        self.df_manual = pd.DataFrame()\n",
    "        self._separate_nodes()\n",
    "\n",
    "    def _extract_intents(self):\n",
    "        self._df[\"intent\"] = self._df[\"conditions\"].astype(str).apply(self._extract_intent)\n",
    "\n",
    "    @staticmethod\n",
    "    def _extract_intent(conditions: str) -> str:\n",
    "        search = re.search(r\"#(\\S+)\", conditions)\n",
    "        return search.group(1) if search else \"\"\n",
    "\n",
    "    def _separate_nodes(self):\n",
    "        \"\"\"\n",
    "        Separates the dataframe into manually added questions, auto-generated ones,\n",
    "        the anything_else node and the root node.\n",
    "        \"\"\"\n",
    "        self.anything_else_node = self._df.parent.isna() & (self._df.conditions == \"anything_else\")\n",
    "        self.generated_nodes = ~self._df.dialog_node.str.match(r\"node_._\")\n",
    "        self.manual_nodes = ~self.generated_nodes & ~self.anything_else_node\n",
    "        self.df_anything_else = self._df[self.anything_else_node].copy()\n",
    "        self.df_generated = self._df[self.generated_nodes].copy()\n",
    "        self.df_manual = self._df[self.manual_nodes].copy()\n",
    "        self.root = (\n",
    "            self.df_manual.previous_sibling.isna()\n",
    "            & self.df_manual.parent.isna()\n",
    "            & self.df_manual.next_step.isna()\n",
    "        )\n",
    "\n",
    "    def _build(self):\n",
    "        \"\"\"Updates the main dataframe to reflect changes in its subparts.\"\"\"\n",
    "        self._df = self.df_manual.append(self.df_generated).append(self.df_anything_else)\n",
    "        self._df.reset_index(drop=True, inplace=True)\n",
    "        self._extract_intents()\n",
    "\n",
    "    @property\n",
    "    def df(self) -> pd.DataFrame:\n",
    "        \"\"\"Returns the main dataframe after building and dropping temporary columns.\"\"\"\n",
    "        self._build()\n",
    "        out = self._df.drop(\n",
    "            columns=[\"fonte\", \"intent\", \"modificador\", \"substantivo\", \"recipiente\"],\n",
    "            errors=\"ignore\",\n",
    "        )\n",
    "        return out\n",
    "\n",
    "    def run(self, intent_limit: int = 0):\n",
    "        self.sort_nodes()\n",
    "        self.limit_intents(intent_limit)\n",
    "        self.set_contexts_node()\n",
    "        self.set_help_node()\n",
    "        self.set_sources()\n",
    "        self.cleanup_previous_siblings()\n",
    "        self.fix_previous_siblings()\n",
    "\n",
    "    def sort_nodes(self):\n",
    "        self.df_manual = self.sort_by_previous_siblings(\n",
    "            df=self.df_manual, root=self.root\n",
    "        )\n",
    "        self.df_generated.sort_values(by=[\"intent\"], inplace=True)\n",
    "        self._build()\n",
    "        self._separate_nodes()\n",
    "        print(\"Nodes sorted!\")\n",
    "\n",
    "    @staticmethod\n",
    "    def sort_by_previous_siblings(df: pd.DataFrame, root: pd.Index):\n",
    "        \"\"\"\n",
    "        Sorts the rows in a dataframe to reflect how the nodes appear on the interface.\n",
    "        \"\"\"\n",
    "        previous_siblings = df.previous_sibling.to_list()\n",
    "        parents = df.parent.to_list()\n",
    "        df.loc[root, \"order\"] = 0\n",
    "\n",
    "        curr = 1\n",
    "        last_node = df[root].dialog_node.values[0]\n",
    "        while df.order.hasnans:\n",
    "            if last_node in parents:\n",
    "                next_node = (df.parent == last_node) & (df.previous_sibling.isna())\n",
    "            elif last_node in previous_siblings:\n",
    "                next_node = df.previous_sibling == last_node\n",
    "            else:\n",
    "                last_parent = df[df.dialog_node == last_node].parent.values[0]\n",
    "                next_node = df.previous_sibling == last_parent\n",
    "            df.loc[next_node, \"order\"] = curr\n",
    "            try:\n",
    "                last_node = df[next_node].dialog_node.values[0]\n",
    "            except IndexError:\n",
    "                break\n",
    "            curr += 1\n",
    "\n",
    "        df.sort_values(by=[\"order\"], inplace=True)\n",
    "        df.drop(\"order\", inplace=True, axis=1)\n",
    "        return df\n",
    "\n",
    "    def set_contexts_node(self):\n",
    "        \"\"\"\n",
    "        Adds contexts to the 'welcome' node which are a mapping of generated nodes'\n",
    "        titles and intents. This enables the 'help' node, which picks random integers\n",
    "        and offers a set of questions to the user.\n",
    "        \"\"\"\n",
    "        df = self.df_generated.reset_index(drop=True)\n",
    "        titles = df.title.to_dict()\n",
    "        intents = df.intent.to_dict()\n",
    "        titles = {str(k): v for k, v in titles.items()}\n",
    "        intents = {str(k): v for k, v in intents.items()}\n",
    "\n",
    "        welcome_node = self.df_manual.conditions.str.contains(\"welcome\").fillna(False)\n",
    "        node_context = self.df_manual.loc[welcome_node, \"context\"].to_list()[0]\n",
    "        node_context[\"titles\"] = titles\n",
    "        node_context[\"intents\"] = intents\n",
    "        self.df_manual.loc[welcome_node, \"context\"] = str(node_context)\n",
    "        print(\"Contexts set!\")\n",
    "\n",
    "    def set_help_node(self, number_of_hints: int=3):\n",
    "        help_node = self.df_manual.conditions.str.contains(\"ajuda\").fillna(False)\n",
    "        number_of_intents = self.df_generated.shape[0]\n",
    "        intents_per_hint = number_of_intents // number_of_hints\n",
    "        node_context = {\n",
    "            f\"dica{i}\": f\"<? new Random().nextInt({intents_per_hint}) +{i * intents_per_hint} ?>\"\n",
    "            for i in range(number_of_hints)\n",
    "        }\n",
    "        self.df_manual.loc[help_node, \"context\"] = str(node_context)\n",
    "        print(\"Help node set!\")\n",
    "\n",
    "    def cleanup_previous_siblings(self):\n",
    "        \"\"\"Removes the previous_sibling field of all nodes except manual ones.\"\"\"\n",
    "        self.df_generated[\"previous_sibling\"] = np.nan\n",
    "        self.df_anything_else[\"previous_sibling\"] = np.nan\n",
    "        print(\"Previous siblings cleaned up!\")\n",
    "\n",
    "    def fix_previous_siblings(self):\n",
    "        \"\"\"\n",
    "        Applies previous_sibling to nodes which don't have one (generated) based on the\n",
    "        node above. Then, connects the generated nodes to the manual nodes and the last\n",
    "        node (anything_else).\n",
    "        \"\"\"\n",
    "        no_upstream = (\n",
    "            self.df_generated.previous_sibling.isna()\n",
    "            & self.df_generated.parent.isna()\n",
    "        )\n",
    "        df_no_upstream = self.df_generated[no_upstream].copy()\n",
    "        df_no_upstream.reset_index(inplace=True)\n",
    "        df_no_upstream.previous_sibling = df_no_upstream.dialog_node.shift(1)\n",
    "\n",
    "        # assign the last manual node as the previous sibling for the first generated node\n",
    "        df_no_upstream.loc[0, \"previous_sibling\"] = self._find_last_root_node(self.df_manual)\n",
    "        df_no_upstream.set_index(\"index\", inplace=True)\n",
    "\n",
    "        # assign the last generated node as the previous sibling for the anything_else node\n",
    "        root_level = self.df_generated.parent.isna()\n",
    "        last_root_generated_node = self.df_generated.loc[root_level, \"dialog_node\"].to_list()[-1]\n",
    "        self.df_anything_else[\"previous_sibling\"] = last_root_generated_node\n",
    "\n",
    "        # overwrites df_generated with values from df_no_upstream based on index\n",
    "        self.df_generated.update(df_no_upstream)\n",
    "        print(\"Previous siblings fixed!\")\n",
    "\n",
    "    @staticmethod\n",
    "    def _find_last_root_node(df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Returns the identifier of the last entry which is a root node (does not have\n",
    "        parents).\n",
    "        \"\"\"\n",
    "        no_parent = df.parent.isna()\n",
    "        no_parent_indices = no_parent.index[no_parent].to_list()\n",
    "        last_no_parent = no_parent_indices.pop()\n",
    "        return df.loc[last_no_parent].dialog_node\n",
    "\n",
    "    def set_sources(self):\n",
    "        \"\"\"\n",
    "        For each generated node, adds a child node which is activated if the user asks\n",
    "        for the source of the information.\n",
    "        \"\"\"\n",
    "        df = self.df_generated.reset_index(drop=False)\n",
    "        sources = df.apply(self._create_source, axis=1, cols=df.columns)\n",
    "        df_with_sources = pd.concat([df, sources])\n",
    "        df_with_sources.set_index(\"index\", inplace=True)\n",
    "        df_with_sources.sort_index(inplace=True)\n",
    "        df_with_sources.reset_index(drop=True, inplace=True)\n",
    "        self.df_generated = df_with_sources\n",
    "        print(\"Sources set!\")\n",
    "\n",
    "    @staticmethod\n",
    "    def _create_source(parent: pd.Series, cols: pd.Index) -> pd.Series:\n",
    "        fontes = parent[\"fonte\"].split(\"--\")\n",
    "        fontes = drop_duplicates(fontes)\n",
    "        if len(fontes) > 1:\n",
    "            answer = \"As fontes dessa resposta são: \" + \", \".join(fontes)\n",
    "        elif len(fontes) > 0:\n",
    "            answer = \"A fonte dessa resposta é: \" + \", \".join(fontes)\n",
    "        else:\n",
    "            answer = \"\"\"\n",
    "                Desculpe, não tenho uma fonte específica para essa resposta.\n",
    "            \"\"\".strip()\n",
    "\n",
    "        content = {\n",
    "            \"index\": parent[\"index\"] + 0.5,\n",
    "            \"type\": \"standard\",\n",
    "            \"title\": \"Fonte\",\n",
    "            \"output\": {\n",
    "                \"generic\": [\n",
    "                    {\n",
    "                        \"values\": [{\"text\": answer}],\n",
    "                        \"response_type\": \"text\",\n",
    "                        \"selection_policy\": \"sequential\",\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "            \"conditions\": \"#fonte\",\n",
    "            \"dialog_node\": f\"node_{uuid.uuid4().hex[:16]}\",\n",
    "            \"parent\": parent[\"dialog_node\"],\n",
    "        }\n",
    "        output = pd.Series(content, index=cols)\n",
    "        return output\n",
    "\n",
    "    def limit_intents(self, limit: int):\n",
    "        \"\"\"\n",
    "        In case there is an intent limit (100 on the lite plan), cuts down on the generated\n",
    "        nodes to respect the maximum number.\n",
    "        \"\"\"\n",
    "        if not limit:\n",
    "            return\n",
    "        manual_intents = self.df_manual.conditions.str.contains(r\"#\\S+\")\n",
    "        self.df_generated.drop(\n",
    "            self.df_generated.tail(limit - manual_intents.sum()), inplace=True\n",
    "        )\n",
    "        self._separate_nodes()\n",
    "        print(\"Intents limited!\")\n",
    "\n",
    "    def get_intents(self) -> list:\n",
    "        \"\"\"Returns a list of the intents used in the dialog nodes.\"\"\"\n",
    "        self._build()\n",
    "        intents = self._df[\"intent\"].to_list()\n",
    "        return drop_duplicates(intents)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "994744bb",
   "metadata": {},
   "source": [
    "## Skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb686cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mix_skills(base, **kwargs):\n",
    "    new = deepcopy(base)\n",
    "    for k, v in kwargs.items():\n",
    "        new[k] = v\n",
    "    return new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91421937",
   "metadata": {},
   "source": [
    "## Rodar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d81b0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = load_questions()\n",
    "questions[~(questions[\"examples\"] == \"\")].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286b35a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_path = \"results/skill-Amazônia-Azul.json\"\n",
    "skill = load_skill(skill_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd75b548",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_intents = get_intents(questions)\n",
    "print(\"Intents obtained!\")\n",
    "mixed_intents = mix_list(skill[\"intents\"], new_intents)\n",
    "print(\"Intents mixed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "new_entities = get_entities(questions)\n",
    "print(\"Entities obtained!\")\n",
    "mixed_entities = mix_list(skill[\"entities\"], new_entities)\n",
    "print(\"Entities mixed!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29124fc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_nodes = get_dialog_nodes(questions)\n",
    "print(\"Nodes obtained!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "old = skill[\"dialog_nodes\"]\n",
    "old = [n for n in old if re.search(r\"node_._\", n[\"dialog_node\"])]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mixed_nodes = mix_list(old, new_nodes)\n",
    "print(\"Nodes mixed!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "node_organizer = NodeOrganizer(mixed_nodes)\n",
    "node_organizer.run()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "used_intents = node_organizer.get_intents()\n",
    "mixed_intents = [intent for intent in mixed_intents if intent[\"intent\"] in used_intents]\n",
    "print(\"Unused intents removed!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b92c569",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mixed_nodes = convert_to_list(node_organizer.df)\n",
    "mixed_skill = mix_skills(\n",
    "    skill,\n",
    "    intents=mixed_intents,\n",
    "    entities=mixed_entities,\n",
    "    dialog_nodes=mixed_nodes,\n",
    ")\n",
    "save_skill(skill_path, mixed_skill)\n",
    "print(\"Finished at\", datetime.now().strftime(\"%H:%M\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "276.475px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "249.85px",
    "left": "903px",
    "right": "20px",
    "top": "68px",
    "width": "543px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}